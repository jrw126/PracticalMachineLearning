---
title: "Practical Machine Learning Project"
author: "John Wright"
date: "Sunday, November 09, 2014"
output: html_document
---

# Load data and libraries
```{r}
library(caret)
library(corrgram)
library(Hmisc)
library(randomForest)

train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
```

## Data Documentation
http://groupware.les.inf.puc-rio.br/har

# Data Cleaning and Feature Selection
Taking a quick visual glance at the train and test sets, it looks like there are many variables in the training set where most of the values are missing and several variables in the test set where _ALL_ of the values are missing. It doesn't make much sense to use a variable to train a model if it won't have any corresponding values in the testing set, so these columns should be identified and removed.

Additionally, since we want this model to be generalizable, it doesn't make sense to use the participant's name as a feature. Perhaps not everyone who's weightlifting performance want to predict is named `r unique(train$user_name)`. Similar logic can be applied to the timestamps and the variable "X", which appears to be a row number.
```{r}
# Column indices of columns that aren't all NA. Also ignores the first 5 columns.
idx <- setdiff(which(!sapply(1:ncol(test), function(x) sum(is.na(test[, x])) == nrow(test))), 1:5)

train <- train[, idx]
test <- test[, idx]

# Make sure the data types between the training and test sets match.
which(!sapply(train,class) == sapply(test,class))

qplot(1:nrow(train), train$pitch_belt, color = train$classe)
```

This data set has lots of numeric variables that may contain nearly the same information as far as prediction is concerned. To isolate these variables, some correlation analysis is performed. First, a correlogram is generated to confirm that there are in fact some highly correlated values. The darkly shaded boxes in the plot confirm that this is true.
```{r}
# Generate correlogram
corrgram(train[, idx], lower.panel = panel.shade, upper.panel = NULL, text.panel = panel.txt, main = "Correlogram")

# Identify the correlated data. Non-numeric columns are ignored.
M <- abs(cor(train[, sapply(train, is.numeric)]))
diag(M) <- 0 
M <- which(M > 0.8, arr.ind = T)

fit <- randomForest(classe ~ ., data = train)
pred <- predict(fit, test)
confusionMatrix(testing$problem_id, pred)

length(unique(row.names(M))) / nrow(M) * 100

```


